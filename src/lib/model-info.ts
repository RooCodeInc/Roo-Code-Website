import { ModelInfo, ProviderName, RooCodeSettings } from "./schemas"

export const MODEL_INFO = {
	anthropic: {
		"claude-3-7-sonnet-20250219:thinking": {
			maxTokens: 128_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsComputerUse: true,
			supportsPromptCache: true,
			inputPrice: 3.0, // $3 per million input tokens
			outputPrice: 15.0, // $15 per million output tokens
			cacheWritesPrice: 3.75, // $3.75 per million tokens
			cacheReadsPrice: 0.3, // $0.30 per million tokens
			thinking: true,
		},
		"claude-3-7-sonnet-20250219": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: true,
			supportsComputerUse: true,
			supportsPromptCache: true,
			inputPrice: 3.0, // $3 per million input tokens
			outputPrice: 15.0, // $15 per million output tokens
			cacheWritesPrice: 3.75, // $3.75 per million tokens
			cacheReadsPrice: 0.3, // $0.30 per million tokens
			thinking: false,
		},
		"claude-3-5-sonnet-20241022": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: true,
			supportsComputerUse: true,
			supportsPromptCache: true,
			inputPrice: 3.0, // $3 per million input tokens
			outputPrice: 15.0, // $15 per million output tokens
			cacheWritesPrice: 3.75, // $3.75 per million tokens
			cacheReadsPrice: 0.3, // $0.30 per million tokens
		},
		"claude-3-5-haiku-20241022": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: false,
			supportsPromptCache: true,
			inputPrice: 1.0,
			outputPrice: 5.0,
			cacheWritesPrice: 1.25,
			cacheReadsPrice: 0.1,
		},
		"claude-3-opus-20240229": {
			maxTokens: 4096,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 15.0,
			outputPrice: 75.0,
			cacheWritesPrice: 18.75,
			cacheReadsPrice: 1.5,
		},
		"claude-3-haiku-20240307": {
			maxTokens: 4096,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 0.25,
			outputPrice: 1.25,
			cacheWritesPrice: 0.3,
			cacheReadsPrice: 0.03,
		},
	},
	bedrock: {
		"amazon.nova-pro-v1:0": {
			maxTokens: 5000,
			contextWindow: 300_000,
			supportsImages: true,
			supportsComputerUse: false,
			supportsPromptCache: true,
			inputPrice: 0.8,
			outputPrice: 3.2,
			cacheWritesPrice: 0.8, // per million tokens
			cacheReadsPrice: 0.2, // per million tokens
			minTokensPerCachePoint: 1,
			maxCachePoints: 1,
			cachableFields: ["system"],
		},
		"amazon.nova-pro-latency-optimized-v1:0": {
			maxTokens: 5000,
			contextWindow: 300_000,
			supportsImages: true,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 1.0,
			outputPrice: 4.0,
			cacheWritesPrice: 1.0, // per million tokens
			cacheReadsPrice: 0.25, // per million tokens
			description: "Amazon Nova Pro with latency optimized inference",
		},
		"amazon.nova-lite-v1:0": {
			maxTokens: 5000,
			contextWindow: 300_000,
			supportsImages: true,
			supportsComputerUse: false,
			supportsPromptCache: true,
			inputPrice: 0.06,
			outputPrice: 0.24,
			cacheWritesPrice: 0.06, // per million tokens
			cacheReadsPrice: 0.015, // per million tokens
			minTokensPerCachePoint: 1,
			maxCachePoints: 1,
			cachableFields: ["system"],
		},
		"amazon.nova-micro-v1:0": {
			maxTokens: 5000,
			contextWindow: 128_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: true,
			inputPrice: 0.035,
			outputPrice: 0.14,
			cacheWritesPrice: 0.035, // per million tokens
			cacheReadsPrice: 0.00875, // per million tokens
			minTokensPerCachePoint: 1,
			maxCachePoints: 1,
			cachableFields: ["system"],
		},
		"anthropic.claude-3-7-sonnet-20250219-v1:0": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: true,
			supportsComputerUse: true,
			supportsPromptCache: true,
			inputPrice: 3.0,
			outputPrice: 15.0,
			cacheWritesPrice: 3.75,
			cacheReadsPrice: 0.3,
			minTokensPerCachePoint: 1024,
			maxCachePoints: 4,
			cachableFields: ["system", "messages", "tools"],
		},
		"anthropic.claude-3-5-sonnet-20241022-v2:0": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: true,
			supportsComputerUse: true,
			supportsPromptCache: true,
			inputPrice: 3.0,
			outputPrice: 15.0,
			cacheWritesPrice: 3.75,
			cacheReadsPrice: 0.3,
			minTokensPerCachePoint: 1024,
			maxCachePoints: 4,
			cachableFields: ["system", "messages", "tools"],
		},
		"anthropic.claude-3-5-haiku-20241022-v1:0": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: false,
			supportsPromptCache: true,
			inputPrice: 0.8,
			outputPrice: 4.0,
			cacheWritesPrice: 1.0,
			cacheReadsPrice: 0.08,
			minTokensPerCachePoint: 2048,
			maxCachePoints: 4,
			cachableFields: ["system", "messages", "tools"],
		},
		"anthropic.claude-3-5-sonnet-20240620-v1:0": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 3.0,
			outputPrice: 15.0,
		},
		"anthropic.claude-3-opus-20240229-v1:0": {
			maxTokens: 4096,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 15.0,
			outputPrice: 75.0,
		},
		"anthropic.claude-3-sonnet-20240229-v1:0": {
			maxTokens: 4096,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 3.0,
			outputPrice: 15.0,
		},
		"anthropic.claude-3-haiku-20240307-v1:0": {
			maxTokens: 4096,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0.25,
			outputPrice: 1.25,
		},
		"anthropic.claude-2-1-v1:0": {
			maxTokens: 4096,
			contextWindow: 100_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 8.0,
			outputPrice: 24.0,
			description: "Claude 2.1",
		},
		"anthropic.claude-2-0-v1:0": {
			maxTokens: 4096,
			contextWindow: 100_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 8.0,
			outputPrice: 24.0,
			description: "Claude 2.0",
		},
		"anthropic.claude-instant-v1:0": {
			maxTokens: 4096,
			contextWindow: 100_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 0.8,
			outputPrice: 2.4,
			description: "Claude Instant",
		},
		"deepseek.r1-v1:0": {
			maxTokens: 32_768,
			contextWindow: 128_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 1.35,
			outputPrice: 5.4,
		},
		"meta.llama3-3-70b-instruct-v1:0": {
			maxTokens: 8192,
			contextWindow: 128_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.72,
			outputPrice: 0.72,
			description: "Llama 3.3 Instruct (70B)",
		},
		"meta.llama3-2-90b-instruct-v1:0": {
			maxTokens: 8192,
			contextWindow: 128_000,
			supportsImages: true,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.72,
			outputPrice: 0.72,
			description: "Llama 3.2 Instruct (90B)",
		},
		"meta.llama3-2-11b-instruct-v1:0": {
			maxTokens: 8192,
			contextWindow: 128_000,
			supportsImages: true,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.16,
			outputPrice: 0.16,
			description: "Llama 3.2 Instruct (11B)",
		},
		"meta.llama3-2-3b-instruct-v1:0": {
			maxTokens: 8192,
			contextWindow: 128_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.15,
			outputPrice: 0.15,
			description: "Llama 3.2 Instruct (3B)",
		},
		"meta.llama3-2-1b-instruct-v1:0": {
			maxTokens: 8192,
			contextWindow: 128_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.1,
			outputPrice: 0.1,
			description: "Llama 3.2 Instruct (1B)",
		},
		"meta.llama3-1-405b-instruct-v1:0": {
			maxTokens: 8192,
			contextWindow: 128_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 2.4,
			outputPrice: 2.4,
			description: "Llama 3.1 Instruct (405B)",
		},
		"meta.llama3-1-70b-instruct-v1:0": {
			maxTokens: 8192,
			contextWindow: 128_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.72,
			outputPrice: 0.72,
			description: "Llama 3.1 Instruct (70B)",
		},
		"meta.llama3-1-70b-instruct-latency-optimized-v1:0": {
			maxTokens: 8192,
			contextWindow: 128_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.9,
			outputPrice: 0.9,
			description: "Llama 3.1 Instruct (70B) (w/ latency optimized inference)",
		},
		"meta.llama3-1-8b-instruct-v1:0": {
			maxTokens: 8192,
			contextWindow: 8_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.22,
			outputPrice: 0.22,
			description: "Llama 3.1 Instruct (8B)",
		},
		"meta.llama3-70b-instruct-v1:0": {
			maxTokens: 2048,
			contextWindow: 8_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 2.65,
			outputPrice: 3.5,
		},
		"meta.llama3-8b-instruct-v1:0": {
			maxTokens: 2048,
			contextWindow: 4_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.3,
			outputPrice: 0.6,
		},
		"amazon.titan-text-lite-v1:0": {
			maxTokens: 4096,
			contextWindow: 8_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.15,
			outputPrice: 0.2,
			description: "Amazon Titan Text Lite",
		},
		"amazon.titan-text-express-v1:0": {
			maxTokens: 4096,
			contextWindow: 8_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.2,
			outputPrice: 0.6,
			description: "Amazon Titan Text Express",
		},
		"amazon.titan-text-embeddings-v1:0": {
			maxTokens: 8192,
			contextWindow: 8_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.1,
			description: "Amazon Titan Text Embeddings",
		},
		"amazon.titan-text-embeddings-v2:0": {
			maxTokens: 8192,
			contextWindow: 8_000,
			supportsImages: false,
			supportsComputerUse: false,
			supportsPromptCache: false,
			inputPrice: 0.02,
			description: "Amazon Titan Text Embeddings V2",
		},
	},
	vertex: {
		"gemini-2.0-flash-001": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0.15,
			outputPrice: 0.6,
		},
		"gemini-2.5-pro-preview-03-25": {
			maxTokens: 65_535,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 2.5,
			outputPrice: 15,
		},
		"gemini-2.5-pro-exp-03-25": {
			maxTokens: 65_535,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-2.0-pro-exp-02-05": {
			maxTokens: 8192,
			contextWindow: 2_097_152,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-2.0-flash-lite-001": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0.075,
			outputPrice: 0.3,
		},
		"gemini-2.0-flash-thinking-exp-01-21": {
			maxTokens: 8192,
			contextWindow: 32_768,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-1.5-flash-002": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0.075,
			outputPrice: 0.3,
		},
		"gemini-1.5-pro-002": {
			maxTokens: 8192,
			contextWindow: 2_097_152,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 1.25,
			outputPrice: 5,
		},
		"claude-3-7-sonnet@20250219:thinking": {
			maxTokens: 64_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsComputerUse: true,
			supportsPromptCache: true,
			inputPrice: 3.0,
			outputPrice: 15.0,
			cacheWritesPrice: 3.75,
			cacheReadsPrice: 0.3,
			thinking: true,
		},
		"claude-3-7-sonnet@20250219": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: true,
			supportsComputerUse: true,
			supportsPromptCache: true,
			inputPrice: 3.0,
			outputPrice: 15.0,
			cacheWritesPrice: 3.75,
			cacheReadsPrice: 0.3,
			thinking: false,
		},
		"claude-3-5-sonnet-v2@20241022": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: true,
			supportsComputerUse: true,
			supportsPromptCache: true,
			inputPrice: 3.0,
			outputPrice: 15.0,
			cacheWritesPrice: 3.75,
			cacheReadsPrice: 0.3,
		},
		"claude-3-5-sonnet@20240620": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 3.0,
			outputPrice: 15.0,
			cacheWritesPrice: 3.75,
			cacheReadsPrice: 0.3,
		},
		"claude-3-5-haiku@20241022": {
			maxTokens: 8192,
			contextWindow: 200_000,
			supportsImages: false,
			supportsPromptCache: true,
			inputPrice: 1.0,
			outputPrice: 5.0,
			cacheWritesPrice: 1.25,
			cacheReadsPrice: 0.1,
		},
		"claude-3-opus@20240229": {
			maxTokens: 4096,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 15.0,
			outputPrice: 75.0,
			cacheWritesPrice: 18.75,
			cacheReadsPrice: 1.5,
		},
		"claude-3-haiku@20240307": {
			maxTokens: 4096,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 0.25,
			outputPrice: 1.25,
			cacheWritesPrice: 0.3,
			cacheReadsPrice: 0.03,
		},
	},
	gemini: {
		"gemini-2.5-pro-exp-03-25": {
			maxTokens: 65_536,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-2.5-pro-preview-03-25": {
			maxTokens: 65_535,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 2.5,
			outputPrice: 15,
		},
		"gemini-2.0-flash-001": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-2.0-flash-lite-preview-02-05": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-2.0-pro-exp-02-05": {
			maxTokens: 8192,
			contextWindow: 2_097_152,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-2.0-flash-thinking-exp-01-21": {
			maxTokens: 65_536,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-2.0-flash-thinking-exp-1219": {
			maxTokens: 8192,
			contextWindow: 32_767,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-2.0-flash-exp": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-1.5-flash-002": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-1.5-flash-exp-0827": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-1.5-flash-8b-exp-0827": {
			maxTokens: 8192,
			contextWindow: 1_048_576,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-1.5-pro-002": {
			maxTokens: 8192,
			contextWindow: 2_097_152,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-1.5-pro-exp-0827": {
			maxTokens: 8192,
			contextWindow: 2_097_152,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
		"gemini-exp-1206": {
			maxTokens: 8192,
			contextWindow: 2_097_152,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 0,
			outputPrice: 0,
		},
	},
	"openai-native": {
		"gpt-4.1": {
			maxTokens: 32_768,
			contextWindow: 1_047_576,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 2,
			outputPrice: 8,
			cacheReadsPrice: 0.5,
		},
		"gpt-4.1-mini": {
			maxTokens: 32_768,
			contextWindow: 1_047_576,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 0.4,
			outputPrice: 1.6,
			cacheReadsPrice: 0.1,
		},
		"gpt-4.1-nano": {
			maxTokens: 32_768,
			contextWindow: 1_047_576,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 0.1,
			outputPrice: 0.4,
			cacheReadsPrice: 0.025,
		},
		o3: {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 10.0,
			outputPrice: 40.0,
			cacheReadsPrice: 2.5,
			reasoningEffort: "medium",
		},
		"o3-high": {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 10.0,
			outputPrice: 40.0,
			cacheReadsPrice: 2.5,
			reasoningEffort: "high",
		},
		"o3-low": {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 10.0,
			outputPrice: 40.0,
			cacheReadsPrice: 2.5,
			reasoningEffort: "low",
		},
		"o4-mini": {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 1.1,
			outputPrice: 4.4,
			cacheReadsPrice: 0.275,
			reasoningEffort: "medium",
		},
		"o4-mini-high": {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 1.1,
			outputPrice: 4.4,
			cacheReadsPrice: 0.275,
			reasoningEffort: "high",
		},
		"o4-mini-low": {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 1.1,
			outputPrice: 4.4,
			cacheReadsPrice: 0.275,
			reasoningEffort: "low",
		},
		"o3-mini": {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: false,
			supportsPromptCache: true,
			inputPrice: 1.1,
			outputPrice: 4.4,
			cacheReadsPrice: 0.55,
			reasoningEffort: "medium",
		},
		"o3-mini-high": {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: false,
			supportsPromptCache: true,
			inputPrice: 1.1,
			outputPrice: 4.4,
			cacheReadsPrice: 0.55,
			reasoningEffort: "high",
		},
		"o3-mini-low": {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: false,
			supportsPromptCache: true,
			inputPrice: 1.1,
			outputPrice: 4.4,
			cacheReadsPrice: 0.55,
			reasoningEffort: "low",
		},
		o1: {
			maxTokens: 100_000,
			contextWindow: 200_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 15,
			outputPrice: 60,
			cacheReadsPrice: 7.5,
		},
		"o1-preview": {
			maxTokens: 32_768,
			contextWindow: 128_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 15,
			outputPrice: 60,
			cacheReadsPrice: 7.5,
		},
		"o1-mini": {
			maxTokens: 65_536,
			contextWindow: 128_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 1.1,
			outputPrice: 4.4,
			cacheReadsPrice: 0.55,
		},
		"gpt-4.5-preview": {
			maxTokens: 16_384,
			contextWindow: 128_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 75,
			outputPrice: 150,
			cacheReadsPrice: 37.5,
		},
		"gpt-4o": {
			maxTokens: 16_384,
			contextWindow: 128_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 2.5,
			outputPrice: 10,
			cacheReadsPrice: 1.25,
		},
		"gpt-4o-mini": {
			maxTokens: 16_384,
			contextWindow: 128_000,
			supportsImages: true,
			supportsPromptCache: true,
			inputPrice: 0.15,
			outputPrice: 0.6,
			cacheReadsPrice: 0.075,
		},
	},
	deepseek: {
		"deepseek-chat": {
			maxTokens: 8192,
			contextWindow: 64_000,
			supportsImages: false,
			supportsPromptCache: true,
			inputPrice: 0.27, // $0.27 per million tokens (cache miss)
			outputPrice: 1.1, // $1.10 per million tokens
			cacheWritesPrice: 0.27, // $0.27 per million tokens (cache miss)
			cacheReadsPrice: 0.07, // $0.07 per million tokens (cache hit).
			description: `DeepSeek-V3 achieves a significant breakthrough in inference speed over previous models. It tops the leaderboard among open-source models and rivals the most advanced closed-source models globally.`,
		},
		"deepseek-reasoner": {
			maxTokens: 8192,
			contextWindow: 64_000,
			supportsImages: false,
			supportsPromptCache: true,
			inputPrice: 0.55, // $0.55 per million tokens (cache miss)
			outputPrice: 2.19, // $2.19 per million tokens
			cacheWritesPrice: 0.55, // $0.55 per million tokens (cache miss)
			cacheReadsPrice: 0.14, // $0.14 per million tokens (cache hit)
			description: `DeepSeek-R1 achieves performance comparable to OpenAI-o1 across math, code, and reasoning tasks. Supports Chain of Thought reasoning with up to 32K tokens.`,
		},
	},
	mistral: {
		"codestral-latest": {
			maxTokens: 256_000,
			contextWindow: 256_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 0.3,
			outputPrice: 0.9,
		},
		"mistral-large-latest": {
			maxTokens: 131_000,
			contextWindow: 131_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 2.0,
			outputPrice: 6.0,
		},
		"ministral-8b-latest": {
			maxTokens: 131_000,
			contextWindow: 131_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 0.1,
			outputPrice: 0.1,
		},
		"ministral-3b-latest": {
			maxTokens: 131_000,
			contextWindow: 131_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 0.04,
			outputPrice: 0.04,
		},
		"mistral-small-latest": {
			maxTokens: 32_000,
			contextWindow: 32_000,
			supportsImages: false,
			supportsPromptCache: false,
			inputPrice: 0.2,
			outputPrice: 0.6,
		},
		"pixtral-large-latest": {
			maxTokens: 131_000,
			contextWindow: 131_000,
			supportsImages: true,
			supportsPromptCache: false,
			inputPrice: 2.0,
			outputPrice: 6.0,
		},
	},
} as const satisfies Record<
	Extract<ProviderName, "anthropic" | "bedrock" | "vertex" | "gemini" | "openai-native" | "deepseek" | "mistral">,
	Record<string, ModelInfo>
>

export const getModelInfo = (settings: RooCodeSettings): ModelInfo | null | undefined => {
	if (settings.apiProvider && settings.apiModelId && MODEL_INFO[settings.apiProvider as keyof typeof MODEL_INFO]) {
		const models = MODEL_INFO[settings.apiProvider as keyof typeof MODEL_INFO]
		return models[settings.apiModelId as keyof typeof models]
	}

	return (
		settings.openRouterModelInfo ||
		settings.glamaModelInfo ||
		settings.requestyModelInfo ||
		settings.unboundModelInfo ||
		settings.openAiCustomModelInfo
	)
}
